{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인스타 태그검색\n",
    "def insta_searching(word):\n",
    "    url = 'https://www.instagram.com/explore/tags/' + word\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome('c:\\chrome\\chromedriver.exe')\n",
    "\n",
    "word = '제주도맛집'\n",
    "url = insta_searching(word)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 첫번째 게시글 클릭\n",
    "def select_first(driver):\n",
    "    first = driver.find_element_by_css_selector('div._9AhH0')\n",
    "    first.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 게시글 정보 가져오기\n",
    "def get_content(driver):\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    try:\n",
    "        content = soup.select('div.C4VMK > span')[0].text\n",
    "    except:\n",
    "        content = ' '\n",
    "    \n",
    "    tags = re.findall(r'#[^\\s#,\\\\]+', content)\n",
    "    date = soup.select('time._1o9PC.Nzb55')[0]['datetime'][:10]\n",
    "    \n",
    "    try:\n",
    "        like = soup.select('div.Nm9Fw > button')[0].text[4:-1]\n",
    "    except:\n",
    "        like = 0\n",
    "        \n",
    "    try:\n",
    "        place = soup.select('div.M30cS')[0].text\n",
    "    except:\n",
    "        place = ''\n",
    "    \n",
    "    data = [content, date, like, place, tags]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 게시글 열기\n",
    "def move_next(driver):\n",
    "    right = driver.find_element_by_css_selector ('a.coreSpriteRightPaginationArrow')\n",
    "    right.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['제주시 #제주또시랑요약 : 정성이 가득담긴 김밥계의 모범생제주도에서 가장 핫하고 먹기 힘든 음식은 의외로 김밥입니다.⠀서울내에도 이름난 김밥집들이 많이 있고,가장 흔하고 편하게 먹을 수 있는 게 김밥인데 정말 이상한 일이죠.⠀서귀포의 오는정김밥은 그 인기를 가장 잘 대변하는 곳으로엄청난 양의 전화를 걸거나 타이밍을 잘 맞춰가야만먹을 수 있는 곳으로 제주도에 가면반드시 인증해야만하는 것들 중 하나였는데요.⠀오늘 소개할 곳은 이런 제주도 김밥의 인기를함께 견인할 감각넘치는 김밥집입니다.⠀편스토랑이라는 방송에서 한지혜씨가 구매하며예약대란이 일어난 제주시의 김밥집 제주 또시랑⠀100% 예약제로 운영되어 미리 전화하여예약을 잡은 뒤 픽업만 하면 되는 시스템⠀평범해보이는 빌라의 초인종을 누르면어느새 손에 들려있는 김밥들⠀인기메뉴라는 야채김밥과 시그니처메뉴인 돌담김밥,또시랑유부를 주문했습니다.⠀얇게 썬 계란지단과 당근, 시금치, 단무지, 햄, 맛살 등기본에 충실한 야채김밥은 예상했던 그 맛이지만제주도의 아이덴티티를 담은 돌담김밥이 꽤나 재밌네요.⠀톳과 흑돼지구이, 흑미를 활용하여 말아낸 돌담김밥은제주의 모습과 맛을 그대로 본딴 듯한데와사비마요소스에 콕 찍어먹으면독특한 식감과 맛이 어울어져 인상적입니다.⠀6가지의 각기 다른 토핑이 어울어진 유부초밥 역시일행과 취향껏 골라먹는 재미가 있네요.⠀맛의 임팩트는 자극적인 맛의 오는정김밥쪽이 강하긴 하지만정성이 담긴 패키징과 젊은 감각 가득한 토핑까지!⠀이제 이 곳을 인증하는 횟수도 늘어날 것 같은 예감이 팍팍제주도의 또 다른 맛! 모두 달려가 봅시다.⠀🥢영업시간 : 매일 9시 - 16시 반🥢주소 : 제주시 기자길 72-1 만경빌 102호🥢문의전화 : 010-2600-8891🥢100% 예약제⠀#먹스타그램 #맛스타그램 #맛집 #맛집추천 #맛집소개 #맛탐영제주 #제주도맛집 #제주맛집 #제주여행 #제주또시랑_맛탐영 #제주도김밥 #제주김밥맛집 #김밥맛집 #김밥 #food', '2021-02-13', 0, '제주시', ['#제주또시랑요약', '#먹스타그램', '#맛스타그램', '#맛집', '#맛집추천', '#맛집소개', '#맛탐영제주', '#제주도맛집', '#제주맛집', '#제주여행', '#제주또시랑_맛탐영', '#제주도김밥', '#제주김밥맛집', '#김밥맛집', '#김밥', '#food']], ['#제주_찐맛집리스트제주에서 알아주는 찐맛집만 들고왔다!얼른 공유해두고 널리널리 퍼뜨리자@공유해놓자!.#선팔하면맞팔 #선팔하면맞팔가요 #맞팔100 #디엠 #좋반환영 #좋반댓 #먹스타 #먹스타그램 #음식스타그램 #likeforlikes #제주맛집 #제주노포맛집 #제주시청맛집 #제주도맛집 #애월맛집 #서귀포맛집 #한림맛집 #성산맛집 #서귀포맛집 #제주도민맛집', '2021-02-12', 0, '', ['#제주_찐맛집리스트제주에서', '#선팔하면맞팔', '#선팔하면맞팔가요', '#맞팔100', '#디엠', '#좋반환영', '#좋반댓', '#먹스타', '#먹스타그램', '#음식스타그램', '#likeforlikes', '#제주맛집', '#제주노포맛집', '#제주시청맛집', '#제주도맛집', '#애월맛집', '#서귀포맛집', '#한림맛집', '#성산맛집', '#서귀포맛집', '#제주도민맛집']]]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "driver = webdriver.Chrome('c:\\chrome\\chromedriver.exe')\n",
    "\n",
    "\n",
    "# 추가) 인스타그램 접속후, 로그인 하기  - \n",
    "driver.get('http://www.instargram.com')\n",
    "time.sleep(2)\n",
    "\n",
    "email = '아이디'   ### 계정 정보 수정 필요\n",
    "input_id = driver.find_elements_by_css_selector('input._2hvTZ.pexuQ.zyHYP')[0]\n",
    "input_id.clear()\n",
    "input_id.send_keys(email)\n",
    "\n",
    "password = '비번' ### 비번 정보 수정 필요\n",
    "input_pw = driver.find_elements_by_css_selector('input._2hvTZ.pexuQ.zyHYP')[1]\n",
    "input_pw.clear()\n",
    "input_pw.send_keys(password)\n",
    "input_pw.submit()\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "word = '제주도맛집'\n",
    "url = insta_searching(word)\n",
    "\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "select_first(driver)\n",
    "\n",
    "results = []\n",
    "\n",
    "target = 10\n",
    "for i in range(target):\n",
    "    try:\n",
    "        data = get_content(driver)\n",
    "        results.append(data)\n",
    "        move_next(driver)\n",
    "        \n",
    "    except:\n",
    "        time.sleep(2)\n",
    "        move_next(driver)\n",
    "    \n",
    "\n",
    "print(results[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = ['content', 'date', 'like', 'place', 'tags']\n",
    "results_df.to_excel('./files/crawling_jejudoMatzip.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeju_insta_df = pd.DataFrame([])\n",
    "\n",
    "folder = './files/'\n",
    "f_list = ['1_crawling_jejudoMatJip.xlsx', '1_crawling_jejudoGwanGwang.xlsx', '1_crawling_jejuMatJip.xlsx', '1_crawling_jejuYeoHang.xlsx']\n",
    "\n",
    "for fname in f_list:\n",
    "    fpath = folder + fname\n",
    "    temp = pd.read_excel(fpath)\n",
    "    jeju_insta_df = jeju_insta_df.append(temp)\n",
    "\n",
    "#print(jeju_insta_df)\n",
    "jeju_insta_df.columns = ['content','date','like','place','tags']\n",
    "\n",
    "# 중복제거\n",
    "jeju_insta_df.drop_duplicates(subset = ['content'], inplace = True)\n",
    "jeju_insta_df.to_excel('./files/crawling_raw.xlsx', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
